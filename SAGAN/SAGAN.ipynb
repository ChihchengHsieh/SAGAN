{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as Data\n",
    "import torchvision.transforms as T\n",
    "from glob import glob\n",
    "import os\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from torchvision.utils import save_image\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "to_img= T.Compose([T.ToPILImage()])\n",
    "to_tensor = T.Compose([T.ToTensor()])\n",
    "load_norm = T.Compose([T.ToTensor(),T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Parser():\n",
    "    #hyperparameters\n",
    "    def __init__(self):\n",
    "        #image setting\n",
    "        self.n_epoch = 50\n",
    "        self.batch_size = 5\n",
    "        self.z_dim = 64\n",
    "        self.n_dim = 64\n",
    "        self.y_dim = 2\n",
    "        self.D_lr = 0.01\n",
    "        self.G_lr = 0.002 # 0.0002\n",
    "        self.b1 = 0.5\n",
    "        self.b2 = 0.999\n",
    "        self.img_size = 64\n",
    "        self.model_save_freq = 1000\n",
    "        self.img_save_freq = 100\n",
    "        self.show_freq = 50\n",
    "        self.model_path = './SAGAN/Model/'\n",
    "        self.img_path = './SAGAN/Image/' \n",
    "        self.conv_dim = 64\n",
    "        self.d_dim = 64\n",
    "        self.D_out_dim = 16\n",
    "        self.train_img_path = \"./data/celeba/\"\n",
    "        self.num_res = 5\n",
    "        self.D_mode = ''\n",
    "        self.G_mode = ''\n",
    "        self.L_mode = ''\n",
    "        self.k = 0\n",
    "        self.lam = 0.001\n",
    "        self.gamma = 0.5\n",
    "        self.model_name = 'SAGAN'\n",
    "        \n",
    "args = Parser()  \n",
    "\n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)\n",
    "if not os.path.exists(args.img_path):\n",
    "    os.makedirs(args.img_path)\n",
    "\n",
    "\n",
    "class CelebADataset(Data.Dataset):\n",
    "    def __init__(self, mode='train', args=None):\n",
    "        \n",
    "        self.image_transform = T.Compose([\n",
    "            T.Resize((args.img_size,args.img_size)),\n",
    "            #T.RandomResizedCrop(args.img_size, scale=(1.0,1.0)),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "        \n",
    "        with open(\"Path_Male.pickle\", 'rb') as f:\n",
    "            self.path ,self.male= pickle.load(f)\n",
    "            print('Loaded')\n",
    "        self.path = self.path[:-2000] if mode == 'train' else self.path[-2000:]\n",
    "        self.male = self.male[:-2000] if mode == 'train' else self.male[-2000:]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        idx = index % len(self.path)\n",
    "        img = self.image_transform(Image.open(os.path.join(args.train_img_path,\n",
    "                                                             self.path[idx])))\n",
    "        \n",
    "        is_male = self.male[idx]\n",
    "        return img, is_male\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def l2normalize(v, eps=1e-12):\n",
    "    return v / (v.norm() + eps)\n",
    "\n",
    "class SpectralNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self, model, name = 'weight', power_iteration = 1):\n",
    "        super(SpectralNorm, self).__init__()\n",
    "        self.model = model\n",
    "        self.name = name\n",
    "        self.power_iteration = power_iteration\n",
    "        self.register_params()\n",
    "        \n",
    "    def register_params(self):\n",
    "        \n",
    "        w = getattr(self.model, self.name)\n",
    "        height = w.shape[0]\n",
    "        width = w.view(height, -1).shape[1]\n",
    "        u = nn.Parameter(w.new(height).normal_(0,1), requires_grad = False)\n",
    "        v = nn.Parameter(w.new(width).normal_(0,1), requires_grad = False)\n",
    "        u.data = l2normalize(u.data)\n",
    "        v.data = l2normalize(v.data) # use .data keep it as nn.Parameters\n",
    "        w_bar = nn.Parameter(w)\n",
    "        del self.model._parameters[self.name]\n",
    "        \n",
    "        self.model.register_parameter(self.name+'_u',u)\n",
    "        self.model.register_parameter(self.name+'_v',v)\n",
    "        self.model.register_parameter(self.name+'_bar',w_bar)\n",
    "        \n",
    "    def update_u_v(self,):\n",
    "        \n",
    "        u = getattr(self.model, self.name + \"_u\")\n",
    "        v = getattr(self.model, self.name + \"_v\")\n",
    "        w = getattr(self.model, self.name + \"_bar\")\n",
    "        \n",
    "        height = w.shape[0]\n",
    "        \n",
    "        for _ in range(self.power_iteration):\n",
    "            v = l2normalize(torch.mv(torch.t(w.view(height,-1)),u))\n",
    "            u = l2normalize(torch.mv(w.view(height,-1),v))\n",
    "        \n",
    "        sigma = u.dot(w.view(height,-1).mv(v))\n",
    "        setattr(self.model, self.name, w/ sigma.expand_as(w))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        self.update_u_v()\n",
    "        return self.model(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# s = SpectralNorm(nn.Conv2d(3,64,3,1,1))\n",
    "# s.model._parameters.keys()\n",
    "\n",
    "class Self_Attn(nn.Module):\n",
    "    # Residule like structure\n",
    "    def __init__(self, dim):\n",
    "        super(Self_Attn, self).__init__()\n",
    "        self.dim = dim\n",
    "        \n",
    "        self.query_conv = nn.Conv2d(dim, dim//8, 1)\n",
    "        self.key_conv = nn.Conv2d(dim, dim//8, 1)\n",
    "        self.value_conv = nn.Conv2d(dim, dim, 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "        self.sm = nn.Softmax(dim= -1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size, C, width, height = x.size()\n",
    "        ## N = Width*Height\n",
    "        \n",
    "        query_out = self.query_conv(x).view(batch_size,-1,width*height).permute(0,2,1) # B,N,C\n",
    "        key_out = self.key_conv(x).view(batch_size,-1,width*height) # B,C,N\n",
    "        energy = torch.bmm(query_out,key_out)\n",
    "        attention = self.sm(energy) # B,N,N\n",
    "        #print(attention.shape)\n",
    "        value_out = self.value_conv(x).view(batch_size,-1,width*height) # B,C,N\n",
    "        out = torch.bmm(value_out,attention.permute(0,2,1)).view(batch_size,C,width,height)\n",
    "        out = self.gamma * out + x\n",
    "        \n",
    "        return out, attention\n",
    "        \n",
    "        \n",
    "# a = torch.randn(5,8,16,16)        \n",
    "# s = Self_Attn(8)        \n",
    "# s(a)       \n",
    "\n",
    "class SpectralNormConvT(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, k, s=1, p=0 ):\n",
    "        super(SpectralNormConvT, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            SpectralNorm(nn.ConvTranspose2d(in_dim, out_dim, k, s, p)),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model1 = nn.Sequential(\n",
    "            SpectralNormConvT(args.z_dim, args.n_dim*8,4),\n",
    "            SpectralNormConvT(args.n_dim*8, args.n_dim*4, 4,2,1),\n",
    "            SpectralNormConvT(args.n_dim*4, args.n_dim*2, 4,2,1),\n",
    "        )\n",
    "        \n",
    "        self.model2 = SpectralNormConvT(args.n_dim*2, args.n_dim, 4,2,1)\n",
    "        \n",
    "        self.model3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(args.n_dim, 3, 4,2,1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "       \n",
    "        self.attn1 = Self_Attn(args.n_dim*2)\n",
    "        self.attn2 = Self_Attn(args.n_dim)\n",
    "        \n",
    "    def forward(self,):\n",
    "        \n",
    "        z = torch.randn(args.batch_size, args.z_dim, 1, 1).to(device)\n",
    "        out = self.model1(z)\n",
    "        out, p1 = self.attn1(out)\n",
    "        out = self.model2(out)\n",
    "        out, p2 = self.attn2(out)\n",
    "        out = self.model3(out)\n",
    "        \n",
    "        return out, p1, p2\n",
    "    \n",
    "\n",
    "# g = Generator()        \n",
    "# g()       \n",
    "\n",
    "class SpectralNormConv(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, k, s=1, p=0 ):\n",
    "        super(SpectralNormConv, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            SpectralNorm(nn.Conv2d(in_dim, out_dim, k, s, p)),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.model1 = nn.Sequential(\n",
    "            SpectralNormConv(3, args.n_dim, 4,2,1),\n",
    "            SpectralNormConv(args.n_dim, args.n_dim*2, 4,2,1),\n",
    "            SpectralNormConv(args.n_dim*2, args.n_dim*4, 4,2,1),\n",
    "        )\n",
    "        \n",
    "        self.model2 = SpectralNormConv(args.n_dim*4, args.n_dim*8, 4,2,1)\n",
    "        \n",
    "        self.model3 = nn.Conv2d(args.n_dim*8, 1, 4)\n",
    "       \n",
    "        self.attn1 = Self_Attn(args.n_dim*4)\n",
    "        self.attn2 = Self_Attn(args.n_dim*8)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.model1(x)\n",
    "        out, p1 = self.attn1(out)\n",
    "        out = self.model2(out)\n",
    "        out, p2 = self.attn2(out)\n",
    "        out = self.model3(out)\n",
    "        return out, p1, p2\n",
    "        \n",
    "# D = Discriminator()        \n",
    "# D(torch.randn(5,3,64,64))      \n",
    "\n",
    "\n",
    "\n",
    "class SAGAN(nn.Module):\n",
    "    \n",
    "    def __init__(self,):\n",
    "        super(SAGAN, self).__init__()\n",
    "        \n",
    "        self.D = Discriminator()\n",
    "        self.G = Generator()\n",
    "        \n",
    "        self.G_optim = optim.Adam(filter( lambda p : p.requires_grad, self.G.parameters()), lr = args.G_lr , betas= (args.b1 ,args.b2))\n",
    "        self.D_optim = optim.Adam(filter( lambda p : p.requires_grad, self.D.parameters()), lr = args.D_lr , betas= (args.b1 ,args.b2))\n",
    "        \n",
    "        self.BCE = nn.BCELoss()\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.train_hist = {}\n",
    "\n",
    "        self.train_hist['G_loss'] = []\n",
    "        self.train_hist['D_loss'] = []\n",
    "        \n",
    "        #self.apply(self.weight_init)\n",
    "        self.progress_photo = []\n",
    "        \n",
    "        \n",
    "    def forward(self, img):\n",
    "        \n",
    "        img = img.to(device)\n",
    "        \n",
    "        ############# Train D #############\n",
    "        \n",
    "        self.D_optim.zero_grad()\n",
    "        D_real, dr1, dr2 = self.D(img)\n",
    "        D_real_loss = F.relu(1.0 - D_real).mean() # Real D gotta be larger\n",
    "        \n",
    "        self.G_img, gf1, gf2 = self.G()\n",
    "        D_fake, df1, df2 = self.D(self.G_img.detach())\n",
    "        D_fake_loss = F.relu(1.0 + D_fake).mean()\n",
    "        \n",
    "        self.D_loss = D_real_loss + D_fake_loss\n",
    "        self.train_hist['D_loss'].append(self.D_loss.item())\n",
    "        self.D_loss.backward()\n",
    "        self.D_optim.step()\n",
    "        \n",
    "        ############# Train G #############\n",
    "        \n",
    "        self.G_optim.zero_grad()\n",
    "        \n",
    "        self.G_img,_,_ = self.G()\n",
    "        D_fake,_,_ = self.D(self.G_img)\n",
    "        \n",
    "        self.G_loss = - D_fake.mean()\n",
    "        self.train_hist['G_loss'].append(self.G_loss.item())\n",
    "        self.G_loss.backward()\n",
    "        self.G_optim.step()\n",
    "        \n",
    "        \n",
    "        self.progress_photo.append(self.G_img[0].detach())\n",
    "        self.progress_photo = self.progress_photo[-args.img_save_freq:]\n",
    "        \n",
    "    def weight_init(self,m):\n",
    "        if type(m) in [nn.Conv2d, nn.ConvTranspose2d, nn.Linear]:\n",
    "            #nn.init.xavier_normal_(m.weight,nn.init.calculate_gain('leaky_relu',param=0.02))\n",
    "            nn.init.kaiming_normal_(m.weight,0.2,nonlinearity='leaky_relu')\n",
    "            \n",
    "    def image_save(self, step):\n",
    "        \n",
    "        img_save_path = args.img_path + args.model_name+\"_Step_\"+str(step)+\".png\"\n",
    "        save_image( torch.stack(self.progress_photo[:args.img_save_freq]), img_save_path , nrow=10, normalize=True, range=(-1,1))\n",
    "        print('Image saved')  \n",
    "        \n",
    "    def model_save(self,step):\n",
    "        path = args.model_path + args.model_name+'_Step_' + str(step) + '.pth'\n",
    "        torch.save({'SAGAN':self.state_dict()}, path)\n",
    "        print('Model saved')\n",
    "        \n",
    "    def load_step_dict(self, step):\n",
    "        \n",
    "        path = args.model_path + args.model_name +'_Step_' + str(step) + '.pth'\n",
    "        self.load_state_dict(torch.load(path, map_location=lambda storage, loc: storage)[args.model_name])\n",
    " \n",
    "    def plot_all_loss(self,step):\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize= (20,8))\n",
    "        for k in self.train_hist.keys():\n",
    "            plt.plot(self.train_hist[k], label= k)\n",
    "        plt.ylabel('Loss',fontsize=15)\n",
    "        plt.xlabel('Number of Steps',fontsize=15)\n",
    "        plt.title('Loss',fontsize=30,fontweight =\"bold\")\n",
    "        plt.legend(loc = 'upper left')\n",
    "        fig.savefig( args.model_name +\"_Loss_\"+str(step)+\".png\")\n",
    "        \n",
    "    def num_all_params(self,):\n",
    "        return sum([param.nelement() for param in self.parameters()])\n",
    "\n",
    "        \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "dataset = CelebADataset(mode='train',args= args)\n",
    "training_loader = DataLoader(dataset,batch_size=args.batch_size,shuffle=True,drop_last=True,pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = SAGAN().to(device)\n",
    "epoch = 0\n",
    "all_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_scheduler = optim.lr_scheduler.StepLR(gan.G_optim,10000,0.5)\n",
    "D_scheduler = optim.lr_scheduler.StepLR(gan.D_optim,10000,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Step [1] | lr [0.002000] | D Loss: [2.0158] | G Loss: [-8.7789] | Time: 1.4s\n",
      "| Step [2] | lr [0.002000] | D Loss: [20.6219] | G Loss: [-1.0834] | Time: 1.2s\n",
      "| Step [3] | lr [0.002000] | D Loss: [2.2380] | G Loss: [1.0682] | Time: 1.2s\n",
      "| Step [4] | lr [0.002000] | D Loss: [2.2134] | G Loss: [0.5541] | Time: 1.1s\n",
      "| Step [5] | lr [0.002000] | D Loss: [1.3950] | G Loss: [0.4213] | Time: 1.2s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-d8beae749f41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mstart_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mgan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mend_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-5627758487c8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mD_real_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mD_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Real D gotta be larger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0mD_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mD_fake_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mD_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-5627758487c8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-5627758487c8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mkey_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# B,C,N\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menergy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# B,N,N\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m#print(attention.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mvalue_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# B,C,N\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel)\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while epoch < args.n_epoch:\n",
    "    for i, (img, _) in enumerate(training_loader):    \n",
    "        \n",
    "        start_t = time.time()\n",
    "        gan(img)\n",
    "        end_t = time.time()\n",
    "        \n",
    "#         G_scheduler.step()\n",
    "#         D_scheduler.step()\n",
    "        \n",
    "        print('| Step [%d] | lr [%.6f] | D Loss: [%.4f] | G Loss: [%.4f] | Time: %.1fs' %\\\n",
    "              ( all_steps, gan.G_optim.param_groups[0]['lr'], gan.D_loss.item(), gan.G_loss.item(),\n",
    "               end_t - start_t))\n",
    "\n",
    "\n",
    "        if all_steps % args.show_freq == 0: #args.show_freq\n",
    "            fig=plt.figure(figsize=(8, 8))\n",
    "            fig.add_subplot(1,3,1)\n",
    "            plt.imshow(to_img(gan.G_img[0].cpu()*0.5+0.5))\n",
    "            plt.show()\n",
    "            if all_steps % args.img_save_freq ==0: # args.img_save_freq\n",
    "                gan.image_save(all_steps)\n",
    "                gan.plot_all_loss('Training')\n",
    "                if all_steps % args.model_save_freq == 0: #args.model_save_freq\n",
    "                    gan.model_save(all_steps)\n",
    "        all_steps += 1\n",
    "        if all_steps > 5000:\n",
    "            raise StopIteration\n",
    "    epoch +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn(4,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0987,  0.2335,  0.5729,  0.0308,  0.0641],\n",
       "         [ 0.1341,  0.0564,  0.0103,  0.5054,  0.2938],\n",
       "         [ 0.3293,  0.1177,  0.1241,  0.1285,  0.3004],\n",
       "         [ 0.2242,  0.3475,  0.0581,  0.2554,  0.1149],\n",
       "         [ 0.0693,  0.0571,  0.6361,  0.1950,  0.0425]],\n",
       "\n",
       "        [[ 0.0518,  0.1474,  0.0609,  0.1812,  0.5586],\n",
       "         [ 0.0294,  0.1768,  0.0867,  0.4244,  0.2827],\n",
       "         [ 0.4157,  0.3649,  0.1275,  0.0759,  0.0159],\n",
       "         [ 0.1243,  0.1547,  0.0750,  0.3159,  0.3301],\n",
       "         [ 0.0213,  0.1902,  0.6178,  0.1290,  0.0417]],\n",
       "\n",
       "        [[ 0.2794,  0.0284,  0.1014,  0.0401,  0.5507],\n",
       "         [ 0.0629,  0.3376,  0.1323,  0.1282,  0.3390],\n",
       "         [ 0.1997,  0.1123,  0.1044,  0.0960,  0.4877],\n",
       "         [ 0.1536,  0.0332,  0.0845,  0.6406,  0.0880],\n",
       "         [ 0.0149,  0.4275,  0.1102,  0.0930,  0.3545]],\n",
       "\n",
       "        [[ 0.0737,  0.1882,  0.0817,  0.5970,  0.0593],\n",
       "         [ 0.1085,  0.1262,  0.2576,  0.0233,  0.4844],\n",
       "         [ 0.2517,  0.3373,  0.0826,  0.0613,  0.2671],\n",
       "         [ 0.3434,  0.0598,  0.0278,  0.1448,  0.4241],\n",
       "         [ 0.1302,  0.3431,  0.0606,  0.2858,  0.1803]]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax(-1)(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
